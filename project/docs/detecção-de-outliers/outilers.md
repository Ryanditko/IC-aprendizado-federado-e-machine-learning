# Detec√ß√£o de Outliers em Aprendizado Federado

## Vis√£o Geral

Este documento apresenta a aplica√ß√£o de t√©cnicas de detec√ß√£o de outliers como mecanismo de defesa contra ataques por envenenamento em sistemas de aprendizado federado. A abordagem baseia-se na identifica√ß√£o de atualiza√ß√µes an√¥malas enviadas por participantes maliciosos.

---

## üìö √çndice

1. [Fundamenta√ß√£o Te√≥rica](#fundamenta√ß√£o-te√≥rica)
2. [T√©cnicas Implementadas](#t√©cnicas-implementadas)
3. [Metodologia de Avalia√ß√£o](#metodologia-de-avalia√ß√£o)
4. [Resultados Experimentais](#resultados-experimentais)
5. [Aplica√ß√£o em Aprendizado Federado](#aplica√ß√£o-em-aprendizado-federado)
6. [Refer√™ncias](#refer√™ncias)

---

## Fundamenta√ß√£o Te√≥rica

### O que s√£o Outliers?

**Outliers** (valores at√≠picos ou anomalias) s√£o observa√ß√µes que apresentam caracter√≠sticas significativamente diferentes do padr√£o predominante nos dados. No contexto de aprendizado federado, outliers podem representar:

- **Participantes maliciosos** enviando atualiza√ß√µes envenenadas
- **Gradientes an√¥malos** que comprometem o modelo global
- **Comportamentos suspeitos** de clientes no sistema distribu√≠do

### Relev√¢ncia para Aprendizado Federado

Em sistemas de aprendizado federado, a detec√ß√£o de outliers √© crucial para:

1. **Seguran√ßa**: Identificar agentes maliciosos antes que comprometam o modelo
2. **Integridade**: Garantir que atualiza√ß√µes refletem dados leg√≠timos
3. **Robustez**: Manter desempenho mesmo sob ataque
4. **Privacidade**: Detectar anomalias sem acessar dados brutos

---

## T√©cnicas Implementadas

### 1. Isolation Forest

**Princ√≠pio**: Isola anomalias atrav√©s de particionamento recursivo aleat√≥rio do espa√ßo de features.

**Caracter√≠sticas**:
- Eficiente para grandes volumes de dados
- N√£o requer defini√ß√£o de m√©trica de dist√¢ncia
- Complexidade: O(n log n)

**Aplica√ß√£o em FL**:
- Detecta atualiza√ß√µes de modelos com padr√µes an√¥malos
- Identifica participantes cujos gradientes divergem significativamente

**Hiperpar√¢metros**:
- `contamination`: Propor√ß√£o esperada de outliers
- `n_estimators`: N√∫mero de √°rvores (default: 100)
- `max_samples`: Tamanho da amostra para cada √°rvore

### 2. Local Outlier Factor (LOF)

**Princ√≠pio**: Calcula densidade local de cada ponto comparada com seus vizinhos.

**Caracter√≠sticas**:
- Detecta outliers locais (contextuais)
- Sens√≠vel a varia√ß√µes de densidade
- Baseado em K-vizinhos mais pr√≥ximos

**Aplica√ß√£o em FL**:
- Identifica participantes com comportamento localmente an√¥malo
- √ötil quando ataques s√£o sutis e contextuais

**Hiperpar√¢metros**:
- `n_neighbors`: N√∫mero de vizinhos (default: 20)
- `contamination`: Taxa esperada de contamina√ß√£o
- `metric`: Dist√¢ncia utilizada (euclidean, manhattan, etc.)

### 3. One-Class SVM

**Princ√≠pio**: Aprende uma fronteira que separa dados normais de outliers usando kernel trick.

**Caracter√≠sticas**:
- Baseado em Support Vector Machines
- Flex√≠vel atrav√©s de diferentes kernels
- Eficaz em espa√ßos de alta dimens√£o

**Aplica√ß√£o em FL**:
- Aprende representa√ß√£o de atualiza√ß√µes leg√≠timas
- Classifica novas atualiza√ß√µes como normais ou an√¥malas

**Hiperpar√¢metros**:
- `nu`: Limite superior de outliers e inferior de support vectors
- `kernel`: Tipo de kernel (rbf, linear, poly, sigmoid)
- `gamma`: Coeficiente do kernel

### 4. Elliptic Envelope

**Princ√≠pio**: Assume que dados normais seguem distribui√ß√£o gaussiana multivariada.

**Caracter√≠sticas**:
- Robusto a estima√ß√£o de covari√¢ncia
- Eficiente computacionalmente
- Adequado para dados com distribui√ß√£o normal

**Aplica√ß√£o em FL**:
- Modela distribui√ß√£o esperada de gradientes leg√≠timos
- Detecta atualiza√ß√µes fora da elipse de confian√ßa

**Hiperpar√¢metros**:
- `contamination`: Propor√ß√£o de outliers esperada
- `support_fraction`: Fra√ß√£o de pontos para estima√ß√£o robusta

### 5. DBSCAN (Density-Based Spatial Clustering)

**Princ√≠pio**: Agrupa pontos baseado em densidade; pontos isolados s√£o outliers.

**Caracter√≠sticas**:
- N√£o requer especificar n√∫mero de clusters
- Identifica outliers como ru√≠do (label = -1)
- Eficaz para dados com estrutura de cluster

**Aplica√ß√£o em FL**:
- Agrupa participantes com comportamento similar
- Identifica participantes isolados como potencialmente maliciosos

**Hiperpar√¢metros**:
- `eps`: Raio m√°ximo para considerar vizinhos
- `min_samples`: M√≠nimo de pontos para formar cluster

---

## Metodologia de Avalia√ß√£o

### Dataset de Valida√ß√£o

**Text-Based Cyber Threat Detection** (Kaggle)
- **Amostras**: 19,940 registros
- **Features**: Textos descrevendo amea√ßas cibern√©ticas
- **Labels**: malware, attack-pattern, threat-actor, vulnerability, tools

### Pipeline de Processamento

```
1. Pr√©-processamento
   ‚îú‚îÄ‚îÄ TF-IDF Vectorization (500 features)
   ‚îú‚îÄ‚îÄ PCA Reduction (50 componentes)
   ‚îî‚îÄ‚îÄ StandardScaler Normalization

2. Detec√ß√£o de Outliers
   ‚îú‚îÄ‚îÄ Aplica√ß√£o de 5 t√©cnicas
   ‚îî‚îÄ‚îÄ Predi√ß√£o: normal (0) vs threat (1)

3. Valida√ß√£o
   ‚îú‚îÄ‚îÄ Compara√ß√£o com labels reais
   ‚îî‚îÄ‚îÄ C√°lculo de m√©tricas

4. An√°lise
   ‚îú‚îÄ‚îÄ Ranking de m√©todos
   ‚îî‚îÄ‚îÄ Trade-offs identificados
```

### M√©tricas de Avalia√ß√£o

1. **Accuracy**: Propor√ß√£o de predi√ß√µes corretas
   ```
   Accuracy = (TP + TN) / (TP + TN + FP + FN)
   ```

2. **Precision**: Propor√ß√£o de outliers detectados que s√£o realmente amea√ßas
   ```
   Precision = TP / (TP + FP)
   ```

3. **Recall**: Propor√ß√£o de amea√ßas reais detectadas
   ```
   Recall = TP / (TP + FN)
   ```

4. **F1-Score**: M√©dia harm√¥nica entre Precision e Recall
   ```
   F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)
   ```

### Interpreta√ß√£o no Contexto FL

| M√©trica | Significado em FL |
|---------|-------------------|
| **TP (True Positive)** | Agente malicioso corretamente identificado |
| **TN (True Negative)** | Participante leg√≠timo corretamente aceito |
| **FP (False Positive)** | Participante leg√≠timo incorretamente rejeitado |
| **FN (False Negative)** | Agente malicioso n√£o detectado (‚ö†Ô∏è cr√≠tico) |

---

## Resultados Experimentais

### Desempenho Comparativo

| Rank | M√©todo | Accuracy | Precision | Recall | F1-Score | Interpreta√ß√£o |
|------|--------|----------|-----------|--------|----------|---------------|
| ü•á | **Elliptic Envelope** | **53.14%** | **49.85%** | **49.88%** | **49.87%** | Melhor equil√≠brio geral |
| ü•à | LOF | 49.51% | 45.96% | 45.96% | 45.96% | Bom para anomalias locais |
| ü•â | DBSCAN | 49.29% | 46.73% | **60.99%** | 52.91% | **Melhor recall** |
| 4 | One-Class SVM | 46.98% | 43.25% | 43.23% | 43.24% | Moderado |
| 5 | Isolation Forest | 45.26% | 41.41% | 41.40% | 41.40% | Mais conservador |

### An√°lise dos Resultados

#### 1. Elliptic Envelope - Melhor M√©todo Geral

**Vantagens**:
- Melhor accuracy (53.14%)
- Equil√≠brio entre precision e recall
- Computacionalmente eficiente

**Limita√ß√µes**:
- Assume distribui√ß√£o gaussiana
- Pode falhar com dados multimodais

**Recomenda√ß√£o**: M√©todo ideal para cen√°rios onde √© necess√°rio equil√≠brio entre detec√ß√£o e falsos alarmes.

#### 2. DBSCAN - Melhor Recall

**Vantagens**:
- Recall de 60.99% (detecta mais amea√ßas)
- N√£o assume distribui√ß√£o espec√≠fica
- Identifica estrutura de clusters

**Limita√ß√µes**:
- Mais falsos positivos (FP)
- Sens√≠vel a hiperpar√¢metros

**Recomenda√ß√£o**: Ideal para cen√°rios cr√≠ticos onde √© inaceit√°vel deixar passar ataques (minimizar FN).

#### 3. Trade-offs Identificados

```
Precision vs Recall:
‚îú‚îÄ‚îÄ Alta Precision ‚Üí Menos falsos alarmes, mas pode perder ataques
‚îú‚îÄ‚îÄ Alto Recall ‚Üí Detecta mais ataques, mas gera falsos alarmes
‚îî‚îÄ‚îÄ F1-Score ‚Üí Busca equil√≠brio

Contexto FL:
‚îú‚îÄ‚îÄ Sistemas cr√≠ticos ‚Üí Priorizar Recall (n√£o deixar passar ataques)
‚îú‚îÄ‚îÄ Sistemas com muitos participantes ‚Üí Priorizar Precision (evitar excesso de rejei√ß√µes)
‚îî‚îÄ‚îÄ Balanceado ‚Üí Usar F1-Score como m√©trica principal
```

### Insights Principais

1. **Desafio da Detec√ß√£o**: Accuracy ~50% indica que textos de amea√ßas e normais possuem overlap significativo no espa√ßo de features.

2. **Import√¢ncia do Pr√©-processamento**: TF-IDF + PCA foi crucial para extrair features relevantes de dados textuais.

3. **Variabilidade entre M√©todos**: Diferen√ßa de at√© 15% em recall entre m√©todos demonstra import√¢ncia da escolha.

4. **Contamina√ß√£o Real**: Com 46.7% de amea√ßas no dataset, o problema √© desafiador e realista.

---

## Aplica√ß√£o em Aprendizado Federado

### Cen√°rio de Ataque por Envenenamento

```
Sistema FL:
‚îú‚îÄ‚îÄ Servidor Central (agregador)
‚îú‚îÄ‚îÄ n Participantes (clientes)
‚îÇ   ‚îú‚îÄ‚îÄ m clientes leg√≠timos
‚îÇ   ‚îî‚îÄ‚îÄ k clientes maliciosos (k << m)
‚îÇ
‚îî‚îÄ‚îÄ Processo de Treinamento:
    1. Servidor distribui modelo global
    2. Clientes treinam localmente
    3. Clientes enviam atualiza√ß√µes (gradientes)
    4. ‚ö†Ô∏è Servidor detecta outliers (AQUI!)
    5. Servidor agrega atualiza√ß√µes leg√≠timas
    6. Modelo global atualizado
```

### Pipeline de Defesa Proposto

#### Fase 1: Coleta de Atualiza√ß√µes
```python
# Pseudo-c√≥digo
updates = []
for client in clients:
    local_update = client.train_local_model()
    updates.append(local_update)
```

#### Fase 2: Detec√ß√£o de Outliers
```python
# Vetoriza√ß√£o de atualiza√ß√µes
update_vectors = vectorize(updates)

# Aplicar detector (exemplo: Elliptic Envelope)
detector = EllipticEnvelope(contamination=0.1)
predictions = detector.fit_predict(update_vectors)

# Identificar outliers
malicious_indices = np.where(predictions == -1)[0]
legitimate_indices = np.where(predictions == 1)[0]
```

#### Fase 3: Agrega√ß√£o Segura
```python
# Agregar apenas atualiza√ß√µes leg√≠timas
safe_updates = [updates[i] for i in legitimate_indices]
global_model = aggregate(safe_updates)
```

### Estrat√©gias de Implementa√ß√£o

#### 1. Detec√ß√£o em N√≠vel de Gradiente

**Abordagem**: Analisar gradientes enviados por cada cliente.

**Features Extra√≠das**:
- Norma L2 do gradiente
- Distribui√ß√£o de valores
- Similaridade com gradientes hist√≥ricos
- Dist√¢ncia para gradiente m√©dio

**Exemplo**:
```python
def extract_gradient_features(gradient):
    return {
        'l2_norm': np.linalg.norm(gradient),
        'mean': np.mean(gradient),
        'std': np.std(gradient),
        'sparsity': np.sum(gradient == 0) / len(gradient)
    }
```

#### 2. Detec√ß√£o em N√≠vel de Cliente

**Abordagem**: Analisar hist√≥rico de comportamento de cada cliente.

**Features Extra√≠das**:
- Consist√™ncia de atualiza√ß√µes ao longo do tempo
- Contribui√ß√£o para converg√™ncia
- Padr√µes de atividade
- Desvios do comportamento m√©dio

#### 3. Ensemble de Detectores

**Abordagem**: Combinar m√∫ltiplas t√©cnicas para decis√£o mais robusta.

**Vota√ß√£o**:
```python
methods = [IsolationForest(), LOF(), EllipticEnvelope()]
votes = []

for method in methods:
    prediction = method.fit_predict(updates)
    votes.append(prediction)

# Decis√£o por maioria
final_decision = np.sign(np.sum(votes, axis=0))
```

### Considera√ß√µes Pr√°ticas

#### 1. Calibra√ß√£o de Contamination

```python
# Estimar contamina√ß√£o baseado em hist√≥rico
historical_attacks = 0.05  # 5% de clientes maliciosos esperados
contamination = historical_attacks * 1.5  # Margem de seguran√ßa
```

#### 2. Adapta√ß√£o Din√¢mica

```python
# Ajustar threshold dinamicamente
if false_positive_rate > threshold:
    contamination *= 0.9  # Relaxar detec√ß√£o
elif missed_attacks > threshold:
    contamination *= 1.1  # Aumentar vigil√¢ncia
```

#### 3. Custo-Benef√≠cio

| Aspecto | Custo de FP (False Positive) | Custo de FN (False Negative) |
|---------|------------------------------|------------------------------|
| **Impacto** | Cliente leg√≠timo rejeitado | Ataque n√£o detectado |
| **Consequ√™ncia** | Redu√ß√£o de dados dispon√≠veis | Modelo comprometido |
| **Severidade** | M√©dia | **Alta** |
| **Estrat√©gia** | Tolerar alguns FPs | Minimizar FNs |

---

## Vantagens e Limita√ß√µes

### Vantagens da Abordagem

‚úÖ **Privacy-Preserving**: N√£o requer acesso a dados brutos dos clientes  
‚úÖ **Escal√°vel**: Complexidade computacional aceit√°vel  
‚úÖ **Flex√≠vel**: M√∫ltiplas t√©cnicas dispon√≠veis  
‚úÖ **Interpret√°vel**: Resultados podem ser analisados e validados  
‚úÖ **Proativo**: Detecta ataques antes de comprometer modelo  

### Limita√ß√µes Identificadas

‚ö†Ô∏è **Ataques Sofisticados**: Advers√°rios podem adaptar estrat√©gia para evitar detec√ß√£o  
‚ö†Ô∏è **Tuning de Hiperpar√¢metros**: Requer ajuste para cada cen√°rio  
‚ö†Ô∏è **Cold Start**: Dificuldade em detectar ataques nos rounds iniciais  
‚ö†Ô∏è **Trade-off FP/FN**: Equil√≠brio delicado entre seguran√ßa e inclus√£o  
‚ö†Ô∏è **Dados Heterog√™neos**: Clientes leg√≠timos com dados muito diferentes podem parecer outliers  

---

## Diretrizes para Implementa√ß√£o

### Passo 1: Caracteriza√ß√£o do Sistema

- [ ] Quantificar n√∫mero de participantes
- [ ] Estimar taxa de contamina√ß√£o esperada
- [ ] Definir m√©tricas de sucesso
- [ ] Estabelecer requisitos de lat√™ncia

### Passo 2: Sele√ß√£o de T√©cnica

| Se... | Ent√£o use... | Porque... |
|-------|-------------|-----------|
| Dados gaussianos | Elliptic Envelope | Eficiente e preciso |
| Ataques localizados | LOF | Detecta anomalias contextuais |
| Requisito: Alto recall | DBSCAN | Maximiza detec√ß√£o |
| Sem distribui√ß√£o assumida | Isolation Forest | N√£o-param√©trico |
| Alta dimensionalidade | One-Class SVM | Kernel trick |

### Passo 3: Valida√ß√£o e Monitoramento

```python
# Sistema de monitoramento
class OutlierMonitor:
    def __init__(self):
        self.history = []
    
    def log_detection(self, round_id, outliers, metrics):
        self.history.append({
            'round': round_id,
            'n_outliers': len(outliers),
            'precision': metrics['precision'],
            'recall': metrics['recall']
        })
    
    def alert_if_anomalous(self):
        recent = self.history[-10:]
        if np.mean([r['n_outliers'] for r in recent]) > threshold:
            send_alert("Spike in outlier detection")
```

### Passo 4: Itera√ß√£o e Melhoria

1. **Coletar M√©tricas**: Accuracy, FP/FN rates, tempo de execu√ß√£o
2. **Analisar Erros**: Investigar falsos positivos e negativos
3. **Ajustar Par√¢metros**: Refinar contamination e hiperpar√¢metros
4. **Validar Continuamente**: Manter modelo de detec√ß√£o atualizado

---

## Trabalhos Futuros

### Extens√µes Propostas

1. **Deep Learning para Detec√ß√£o**
   - Autoencoders para aprender representa√ß√µes
   - GANs para gerar ataques sint√©ticos
   - RNNs para capturar padr√µes temporais

2. **Detec√ß√£o Federada**
   - Detectores treinados de forma federada
   - Compartilhamento seguro de padr√µes de ataque
   - Collaborative outlier detection

3. **Defesas Adaptativas**
   - Detectores que evoluem com ataques
   - Aprendizado por refor√ßo para otimizar thresholds
   - Meta-learning para generalizar entre dom√≠nios

4. **Integra√ß√£o com Outras Defesas**
   - Combina√ß√£o com differential privacy
   - Uso conjunto com Byzantine-tolerant aggregation
   - Verifica√ß√£o criptogr√°fica de atualiza√ß√µes

---

## Refer√™ncias

### Artigos Principais

[1] **Blanchard, P., et al. (2017)**. "Machine learning with adversaries: Byzantine tolerant gradient descent." *NeurIPS*.

[2] **Fung, C., et al. (2018)**. "Mitigating sybils in federated learning poisoning." *arXiv preprint*.

[3] **Zhang, J., et al. (2022)**. "A survey on federated learning: The journey from centralized to distributed on-site learning and beyond." *IEEE Internet of Things Journal*.

[4] **Yazdinejad, A., et al. (2024)**. "Federated learning for cybersecurity: Concepts, challenges, and future directions." *IEEE Access*.

### T√©cnicas de Detec√ß√£o

[5] **Liu, F. T., et al. (2008)**. "Isolation forest." *ICDM*.

[6] **Breunig, M. M., et al. (2000)**. "LOF: identifying density-based local outliers." *SIGMOD*.

[7] **Sch√∂lkopf, B., et al. (2001)**. "Estimating the support of a high-dimensional distribution." *Neural Computation*.

[8] **Rousseeuw, P. J., & Driessen, K. V. (1999)**. "A fast algorithm for the minimum covariance determinant estimator." *Technometrics*.

[9] **Ester, M., et al. (1996)**. "A density-based algorithm for discovering clusters." *KDD*.

---

## Conclus√£o

A detec√ß√£o de outliers representa uma abordagem **promissora e pr√°tica** para mitigar ataques por envenenamento em aprendizado federado. Os experimentos demonstraram que:

1. ‚úÖ **Elliptic Envelope** oferece melhor equil√≠brio (F1: 49.87%)
2. ‚úÖ **DBSCAN** maximiza recall (60.99%) para cen√°rios cr√≠ticos
3. ‚úÖ T√©cnicas s√£o **computacionalmente vi√°veis** para implementa√ß√£o real
4. ‚úÖ Abordagem preserva **privacidade** dos participantes

**Recomenda√ß√£o Final**: Implementar sistema de detec√ß√£o **ensemble** combinando Elliptic Envelope (decis√£o prim√°ria) e DBSCAN (valida√ß√£o secund√°ria), com thresholds ajust√°veis baseados no contexto de aplica√ß√£o.

---

**Projeto**: Mitiga√ß√£o de Ataques por Envenenamento em Aprendizado Federado  
**Institui√ß√£o**: Faculdade Impacta  
**Data**: Outubro 2025  
**Autor**: Projeto de Inicia√ß√£o Cient√≠fica
