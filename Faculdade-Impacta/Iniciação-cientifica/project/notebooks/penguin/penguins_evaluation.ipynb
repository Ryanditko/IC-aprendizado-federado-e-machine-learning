{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab7bd2ae",
   "metadata": {},
   "source": [
    "# Avaliação do Dataset Penguins\n",
    "\n",
    "Este notebook apresenta a análise completa e visualizações dos resultados obtidos com o dataset Penguins, incluindo:\n",
    "- Aprendizado Supervisionado\n",
    "- Aprendizado Não Supervisionado\n",
    "- Métricas de Avaliação\n",
    "- Comparações entre Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51536521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    silhouette_score, davies_bouldin_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuração\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628470ad",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Exploração dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset Penguins\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(f\"Dataset Penguins\")\n",
    "print(f\"Amostras originais: {len(df)}\")\n",
    "print(f\"Features: {df.columns.tolist()}\")\n",
    "\n",
    "# Remover valores faltantes\n",
    "df_clean = df.dropna()\n",
    "print(f\"Amostras após limpeza: {len(df_clean)}\")\n",
    "\n",
    "print(f\"\\nDistribuição das Espécies:\")\n",
    "print(df_clean['species'].value_counts())\n",
    "\n",
    "print(f\"\\nDistribuição por Ilha:\")\n",
    "print(df_clean['island'].value_counts())\n",
    "\n",
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaee1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise exploratória visual\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Bill length vs Bill depth\n",
    "for species in df_clean['species'].unique():\n",
    "    data = df_clean[df_clean['species'] == species]\n",
    "    axes[0, 0].scatter(data['bill_length_mm'], data['bill_depth_mm'], \n",
    "                       label=species, alpha=0.6, s=50)\n",
    "axes[0, 0].set_xlabel('Bill Length (mm)', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Bill Depth (mm)', fontweight='bold')\n",
    "axes[0, 0].set_title('Bill Dimensions', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Flipper length vs Body mass\n",
    "for species in df_clean['species'].unique():\n",
    "    data = df_clean[df_clean['species'] == species]\n",
    "    axes[0, 1].scatter(data['flipper_length_mm'], data['body_mass_g'], \n",
    "                       label=species, alpha=0.6, s=50)\n",
    "axes[0, 1].set_xlabel('Flipper Length (mm)', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Body Mass (g)', fontweight='bold')\n",
    "axes[0, 1].set_title('Body Dimensions', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Distribuição por ilha\n",
    "pd.crosstab(df_clean['island'], df_clean['species']).plot(kind='bar', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Distribuição por Ilha', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Ilha', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Contagem', fontweight='bold')\n",
    "axes[1, 0].legend(title='Espécie')\n",
    "\n",
    "# Distribuição por sexo\n",
    "pd.crosstab(df_clean['sex'], df_clean['species']).plot(kind='bar', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Distribuição por Sexo', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Sexo', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Contagem', fontweight='bold')\n",
    "axes[1, 1].legend(title='Espécie')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('penguins_exploratory.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Análise exploratória concluída\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cfbdfd",
   "metadata": {},
   "source": [
    "## 2. Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16bcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar features numéricas\n",
    "numeric_features = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "X_numeric = df_clean[numeric_features].values\n",
    "\n",
    "# Codificar variáveis categóricas\n",
    "le_island = LabelEncoder()\n",
    "le_sex = LabelEncoder()\n",
    "island_encoded = le_island.fit_transform(df_clean['island']).reshape(-1, 1)\n",
    "sex_encoded = le_sex.fit_transform(df_clean['sex']).reshape(-1, 1)\n",
    "\n",
    "# Combinar features\n",
    "X = np.hstack([X_numeric, island_encoded, sex_encoded])\n",
    "\n",
    "# Target\n",
    "le_species = LabelEncoder()\n",
    "y = le_species.fit_transform(df_clean['species'])\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Classes: {le_species.classes_}\")\n",
    "print(\"✓ Dados preparados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e988197",
   "metadata": {},
   "source": [
    "## 3. Aprendizado Supervisionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e043f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split e normalização\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Modelos\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"K-NN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results_supervised = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    results_supervised.append({\n",
    "        'Modelo': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'F1-Score': f1_score(y_test, y_pred, average='weighted')\n",
    "    })\n",
    "\n",
    "df_supervised = pd.DataFrame(results_supervised)\n",
    "print(\"\\nResultados - Aprendizado Supervisionado:\")\n",
    "print(df_supervised.round(4).to_string(index=False))\n",
    "\n",
    "df_supervised.to_csv('penguins_supervised_results.csv', index=False)\n",
    "print(\"\\n✓ Resultados salvos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ee333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização supervisionada\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    bars = ax.bar(df_supervised['Modelo'], df_supervised[metric], color='lightcoral', edgecolor='black')\n",
    "    \n",
    "    ax.axhline(y=0.70, color='red', linestyle='--', linewidth=2, label='Meta 70%')\n",
    "    \n",
    "    for bar, value in zip(bars, df_supervised[metric]):\n",
    "        if value >= 0.70:\n",
    "            bar.set_color('green')\n",
    "            bar.set_alpha(0.7)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel(metric, fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{metric} por Modelo - Penguins Dataset', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticklabels(df_supervised['Modelo'], rotation=45, ha='right')\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('penguins_supervised_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualização salva\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f660b",
   "metadata": {},
   "source": [
    "## 4. Aprendizado Não Supervisionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686186f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar apenas features numéricas para clustering\n",
    "X_scaled = StandardScaler().fit_transform(X_numeric)\n",
    "\n",
    "# K-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters_kmeans = kmeans.fit_predict(X_scaled)\n",
    "silhouette_kmeans = silhouette_score(X_scaled, clusters_kmeans)\n",
    "davies_bouldin_kmeans = davies_bouldin_score(X_scaled, clusters_kmeans)\n",
    "\n",
    "print(f\"K-Means:\")\n",
    "print(f\"  Silhouette: {silhouette_kmeans:.4f}\")\n",
    "print(f\"  Davies-Bouldin: {davies_bouldin_kmeans:.4f}\")\n",
    "\n",
    "# Hierarchical\n",
    "hierarchical = AgglomerativeClustering(n_clusters=3, linkage='average')\n",
    "clusters_hier = hierarchical.fit_predict(X_scaled)\n",
    "silhouette_hier = silhouette_score(X_scaled, clusters_hier)\n",
    "davies_bouldin_hier = davies_bouldin_score(X_scaled, clusters_hier)\n",
    "\n",
    "print(f\"\\nHierarchical:\")\n",
    "print(f\"  Silhouette: {silhouette_hier:.4f}\")\n",
    "print(f\"  Davies-Bouldin: {davies_bouldin_hier:.4f}\")\n",
    "\n",
    "results_unsupervised = pd.DataFrame({\n",
    "    'Método': ['K-Means', 'Hierarchical'],\n",
    "    'Silhouette Score': [silhouette_kmeans, silhouette_hier],\n",
    "    'Davies-Bouldin Index': [davies_bouldin_kmeans, davies_bouldin_hier]\n",
    "})\n",
    "\n",
    "results_unsupervised.to_csv('penguins_unsupervised_results.csv', index=False)\n",
    "print(\"\\n✓ Resultados salvos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49cbcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização clustering\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Real\n",
    "scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', s=50, alpha=0.7, edgecolors='k')\n",
    "axes[0].set_title('Classes Reais - Penguins', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "plt.colorbar(scatter1, ax=axes[0])\n",
    "\n",
    "# K-Means\n",
    "pca_full = PCA(n_components=X_scaled.shape[1])\n",
    "X_pca_full = pca_full.fit_transform(X_scaled)\n",
    "centroids_pca = pca.transform(scaler.inverse_transform(kmeans.cluster_centers_))\n",
    "\n",
    "scatter2 = axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=clusters_kmeans, cmap='viridis', s=50, alpha=0.7, edgecolors='k')\n",
    "axes[1].set_title(f'K-Means\\n(Silhouette: {silhouette_kmeans:.3f})', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "plt.colorbar(scatter2, ax=axes[1])\n",
    "\n",
    "# Hierarchical\n",
    "scatter3 = axes[2].scatter(X_pca[:, 0], X_pca[:, 1], c=clusters_hier, cmap='viridis', s=50, alpha=0.7, edgecolors='k')\n",
    "axes[2].set_title(f'Hierarchical\\n(Silhouette: {silhouette_hier:.3f})', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "axes[2].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "plt.colorbar(scatter3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('penguins_clustering_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Clustering visualizado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340c8fb6",
   "metadata": {},
   "source": [
    "## 5. PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e54073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA completo\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_scaled)\n",
    "\n",
    "var_exp = pca_full.explained_variance_ratio_\n",
    "var_cum = np.cumsum(var_exp)\n",
    "\n",
    "print(\"Análise PCA:\")\n",
    "for i, (var, cum) in enumerate(zip(var_exp, var_cum)):\n",
    "    print(f\"  PC{i+1}: {var:.4f} ({var*100:.2f}%) | Acum: {cum:.4f} ({cum*100:.2f}%)\")\n",
    "\n",
    "n_comp_95 = (var_cum >= 0.95).argmax() + 1\n",
    "print(f\"\\nComponentes para 95%: {n_comp_95}\")\n",
    "\n",
    "# Visualização\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].bar(range(1, len(var_exp)+1), var_exp, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Componente', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Variância Explicada', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Variância por Componente - Penguins', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[1].plot(range(1, len(var_cum)+1), var_cum, marker='o', linewidth=2, markersize=8, color='darkorange')\n",
    "axes[1].axhline(y=0.95, color='red', linestyle='--', linewidth=2, label='95%')\n",
    "axes[1].axvline(x=n_comp_95, color='green', linestyle='--', linewidth=2, label=f'{n_comp_95} Comp.')\n",
    "axes[1].set_xlabel('Número de Componentes', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Variância Acumulada', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Variância Acumulada - Penguins', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('penguins_pca_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ PCA salvo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee65280",
   "metadata": {},
   "source": [
    "## 6. Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7399b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RESUMO - DATASET PENGUINS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. SUPERVISIONADO:\")\n",
    "best = df_supervised.loc[df_supervised['Accuracy'].idxmax()]\n",
    "print(f\"   Melhor: {best['Modelo']}\")\n",
    "print(f\"   Accuracy: {best['Accuracy']:.4f}\")\n",
    "print(f\"   Modelos >= 70%: {(df_supervised['Accuracy'] >= 0.70).sum()}/{len(df_supervised)}\")\n",
    "\n",
    "print(\"\\n2. NÃO SUPERVISIONADO:\")\n",
    "print(f\"   K-Means: {silhouette_kmeans:.4f}\")\n",
    "print(f\"   Hierarchical: {silhouette_hier:.4f}\")\n",
    "\n",
    "print(\"\\n3. PCA:\")\n",
    "print(f\"   Componentes (95%): {n_comp_95}\")\n",
    "print(f\"   PC1+PC2: {var_cum[1]*100:.2f}%\")\n",
    "\n",
    "print(\"\\n4. ARQUIVOS:\")\n",
    "print(\"   ✓ penguins_exploratory.png\")\n",
    "print(\"   ✓ penguins_supervised_metrics.png\")\n",
    "print(\"   ✓ penguins_clustering_comparison.png\")\n",
    "print(\"   ✓ penguins_pca_analysis.png\")\n",
    "print(\"   ✓ CSVs de resultados\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONCLUÍDO\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
